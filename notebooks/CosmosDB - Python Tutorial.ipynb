{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for Cosmos DB and Python for the SQL API\n",
    "\n",
    "As you probably know, [Cosmos DB](https://docs.microsoft.com/en-us/azure/cosmos-db/) is a globally distributed, multi-model database service in Azure that supports document, key-value, wide-column, and graph databases.\n",
    "\n",
    "Cosmos DB includes support for multiple Software Development Kits for programming languages such as Python. Multiple resources already exist that help to learn to use the Python SDK: \n",
    "\n",
    "* [Cosmos DB reference guide for the Python SDK](https://docs.microsoft.com/en-us/python/api/azure-cosmos/?view=azure-python)\n",
    "* [Cosmos DB samples with the Python SDK](https://github.com/Azure/azure-cosmos-python/blob/master/test/crud_tests.py)\n",
    "* [EDX course for Cosmos DB](https://courses.edx.org/courses/course-v1:Microsoft+DAT237x+2T2017/course/): most of the examples in this book come from this EDX course, feel free to go to the course to deepen in the concepts presented in this notebook.\n",
    "\n",
    "\n",
    "## Why a Jupyter Notebook?\n",
    "\n",
    "As opposed to documentation or code samples, Jupyter Notebooks offer a very interesting combination of rich text for explanations and pieces of code that can be executed independently from each other, which makes it ideal to learn a new technology.\n",
    "\n",
    "This notebook will go over the basic (and not so basic) concepts of using Cosmos DB with its Python SDK for the SQL API. You can run this repository from any system with Python 3.x, or using the free platform [Azure Notebooks](https://notebooks.azure.com/), where you have the option of importing Github repositories.\n",
    "\n",
    "Feel free to try some different variations of the code in this notebook, to see different effects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating your Cosmos DB account\n",
    "\n",
    "All Cosmos databases are contained in a Cosmos DB account. You can create a Cosmos DB account in Azure using any Azure mechanism. In this notebook we will assume that you have installed the [Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest), and use it to create a new resource group and a Cosmos DB account. But first things first, you need to login to Azure, and select the subscription you want to use\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set -s \"your subscription name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now set some variables containing the name of the resource group we will use, the name of the Cosmos DB account to be created, the name for a database and for a collection. Consider that the name for your CosmosDB must be globally unique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg         = \"cosmoslab\"\n",
    "location   = \"westeurope\"\n",
    "\n",
    "account    = \"mycosmos1138\"\n",
    "db_name    = \"ecommerce\"\n",
    "coll_name  = \"customers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can create our resource group and Cosmos DB account. When creating the account there some attributes you can defined, such as the type of CosmosDB and API (in this case we will use the SQL API aka DocumentDB), the locations (in this example we will use only one region).\n",
    "\n",
    "Creating the account will take some minutes, please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az group create -n \"$rg\" -l \"$location\"\n",
    "!az cosmosdb create -g \"$rg\" -n \"$account\" --locations \"$location\"=0 --kind GlobalDocumentDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify Cosmos DB account\n",
    "\n",
    "After creating an account, you can modify it, for example to add new read or write regions. In this example we will add a second read region with a failover priority of 1. Note other interesting attributes, such as the default consistency level (session) or different failover properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!az cosmosdb update -g \"$rg\" -n \"$account\" --locations \"$location\"=0 northeurope=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can have a look at the help for the `az cosmosdb update` command for more options to update existing Cosmos DB accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!az cosmosdb update -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "Authentication to a Cosmos DB account works using an account key. There are two account keys for key rotation. You can use the Azure CLI to get the key for an existing account, in this case we get the primary key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_key = !az cosmosdb list-keys -g $rg -n $account --query primaryMasterKey -o tsv\n",
    "# Per default the output is a list, keep only the first item\n",
    "account_key = str(account_key[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client\n",
    "\n",
    "You can create databases and collections using the Azure CLI too, or using the Python SDK already. Since this notebook is about Python, let us use the Python SDK already for this.\n",
    "\n",
    "The first thing we need is to initialize the client, with the Cosmos DB account endpoint (that you can derive from the name, or use the Azure CLI to find out), and the master key that we already got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Building the endpoint as a string\n",
    "cosmosdb_endpoint = \"https://{0}.documents.azure.com\".format(account)\n",
    "print(cosmosdb_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Getting the endpoint with the Azure CLI\n",
    "cosmosdb_endpoint = ! az cosmosdb show -g $rg -n $account --query documentEndpoint -o tsv\n",
    "cosmosdb_endpoint = str(cosmosdb_endpoint[0])\n",
    "print(cosmosdb_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before initializaing the client, let us make sure that we have all required Python dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the [reference page for the CosmosClient method](https://docs.microsoft.com/python/api/azure-cosmos/azure.cosmos.cosmos_client.cosmosclient?view=azure-python#createdatabase-database--options-none-), other than the URL and the authentication you can supply a [connection policy](https://docs.microsoft.com/en-us/python/api/azure-cosmos/azure.cosmos.documents.connectionpolicy?view=azure-python) and the consistency level to use.\n",
    "\n",
    "The connection policy is especially interesting, since it allows defining attributes such as a list of preferred locations to use (typically the closest geographically to the application), disable SSL verification or retry options, amongst others. Refer to the [reference documentation](https://docs.microsoft.com/en-us/python/api/azure-cosmos/azure.cosmos.documents.connectionpolicy?view=azure-python) for more information on the connection policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cosmos.cosmos_client as cosmos_client\n",
    "\n",
    "client = cosmos_client.CosmosClient(url_connection=cosmosdb_endpoint, auth={'masterKey': account_key})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Database and Collection\n",
    "\n",
    "With an initialized client we can now create a database and a collection. Note that you can allocate a performance to the database or to the collection. In this example we will allocate the minimum allowed performance (400 RU/s) to the collection.\n",
    "\n",
    "See the reference guide for the [createDatabase method](https://docs.microsoft.com/en-us/python/api/azure-cosmos/azure.cosmos.cosmos_client.cosmosclient?view=azure-python#createdatabase-database--options-none-) and for the [createContainer method](https://docs.microsoft.com/en-us/python/api/azure-cosmos/azure.cosmos.cosmos_client.cosmosclient?view=azure-python#createcontainer--link--collection--options-none-).\n",
    "\n",
    "Note how when creating a container (called \"collection\" for document-based schemas) you specify some attributes as part as the collection definition (such as the partition key or the indexing), and others as options (such as the throughput).\n",
    "\n",
    "Note that in this example we use the property \"source\" as partition key. This is probably not an ideal partition scheme as we will see during the rest of the notebook, but please do not change this, otherwise some exercises in the notebook will not work as designed. You can find more information about partitions in Cosmos DB [here](https://docs.microsoft.com/azure/cosmos-db/partitioning-overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_definition = { 'id': db_name }\n",
    "created_db = client.CreateDatabase(database_definition)\n",
    "db_link=created_db['_self']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before creating the collection, this code makes sure it does not exist before\n",
    "# Otherwise it gives out an error, that you could grab in a try/catch block as well\n",
    "coll_query = \"select * from r where r.id = '{0}'\".format(coll_name)\n",
    "coll = list(client.QueryContainers(db_link, coll_query))\n",
    "if coll:\n",
    "    print(\"Collection\", coll_name, \"already exists\")\n",
    "else:\n",
    "    collection_definition = {\n",
    "        'id': coll_name, \n",
    "        'indexingPolicy': {'indexingMode': 'consistent'},\n",
    "        'partitionKey': {\n",
    "            'paths': [\n",
    "              '/source'\n",
    "            ],\n",
    "            'kind': 'Hash'\n",
    "        }\n",
    "    }\n",
    "    collection_options = { 'offerThroughput': 400 }\n",
    "    created_collection = client.CreateContainer(created_db['_self'], collection_definition, collection_options)\n",
    "    print(\"Collection\", coll_name, \"has been created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get an existing database or collection\n",
    "\n",
    "If you are working with an existing database or collection, you just need to retrieve them. The retrieved object will have an s_id field that you can use to verify whether the database and collections where found or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the DB link\n",
    "db_query = \"select * from r where r.id = '{0}'\".format(db_name)\n",
    "db = list(client.QueryDatabases(db_query))\n",
    "if db:\n",
    "    db_link = db[0]['_self']\n",
    "    print(\"Database\", db_name, \"found\")\n",
    "    # Uncomment the next line to see the full object\n",
    "    # print(db[0])\n",
    "\n",
    "    # If the database has been found, try to find the collection\n",
    "    coll_query = \"select * from r where r.id = '{0}'\".format(coll_name)\n",
    "    coll = list(client.QueryContainers(db_link, coll_query))\n",
    "    if coll:\n",
    "        coll_link = coll[0]['_self']\n",
    "        print(\"Collection\", coll_name, \"found:\")\n",
    "        print(\" - Indexing policy - Mode:\", coll[0]['indexingPolicy']['indexingMode'])\n",
    "        print(\" - Indexing policy - Mode:\", coll[0]['indexingPolicy']['automatic'])\n",
    "        print(\" - Conflict resolution policy mode:\", coll[0]['conflictResolutionPolicy']['mode'])\n",
    "        # Uncomment the next line to see the full object\n",
    "        # print(coll[0])\n",
    "    else:\n",
    "        print(\"Collection\", coll_name, \"not found :(\")\n",
    "else:\n",
    "    print(\"Database\", db_name, \"not found :(\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively to the QueryContainers method, you can craft manually a collection link with the database and collection names, and use the method ReadCollection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_link='dbs/{0}/colls/{1}/'.format(db_name, coll_name)\n",
    "print(\"Collection link:\", coll_link)\n",
    "collection = client.ReadContainer(coll_link)\n",
    "print(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting an existing database or collection\n",
    "\n",
    "If you want to play with the different options to create a collection, you can modify most of its attributes, with the notable exception of the partition key. If you need to try the commands above with different options you might have to delete the collection first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete only a specific collection\n",
    "coll_query = \"select * from r where r.id = '{0}'\".format(coll_name)\n",
    "coll = list(client.QueryContainers(db_link, coll_query))\n",
    "if coll:\n",
    "    coll_link = coll[0]['_self']\n",
    "    client.DeleteContainer(coll_link)\n",
    "    print(\"Collection\", coll_name, \"has been deleted\")\n",
    "else:\n",
    "    print(\"Collection\", coll_name, \"could not be found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the DB exists, delete it (including any collections)\n",
    "db_query = \"select * from r where r.id = '{0}'\".format(db_name)\n",
    "db = list(client.QueryDatabases(db_query))\n",
    "if db:\n",
    "    db_link = db[0]['_self']\n",
    "    client.DeleteDatabase(db_link)\n",
    "    print(\"Database\", db_name, \"and all its collections have been deleted\")\n",
    "else:\n",
    "    print(\"Database\", db_name, \"could not be found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the RUs of an existing collection\n",
    "\n",
    "You might want to update the performance (throughput) of your collection under certain circumstances, for example occasionally to perform a performance-intensive operation such as a data import or export, or just because you need more performance on your database on a consistent basis.\n",
    "\n",
    "To read the current throughput of an existing collection you can use the QueryOffers method, and update it with the ReplaceOffers method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_query = \"select * from r where r.id = '{0}'\".format(coll_name)\n",
    "coll = list(client.QueryContainers(db_link, coll_query))\n",
    "if coll:\n",
    "    # We found our collection, get the link and find the offers\n",
    "    coll_link = coll[0]['_self']\n",
    "    offer = list(client.QueryOffers('SELECT * FROM c WHERE c.resource = \\'{0}\\''.format(coll_link)))[0]\n",
    "    print(\"Collection\", coll_name, \"found provisioned with\", str(offer['content']['offerThroughput']), \"RU/s\")\n",
    "else:\n",
    "    print(\"Collection\", coll_name, \"not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_offer = offer\n",
    "new_offer['content']['offerThroughput'] += 50\n",
    "throughput = new_offer['content']['offerThroughput']\n",
    "if (throughput >= 400) and (throughput <= 100000) and ((throughput % 100) == 0): \n",
    "    offer = client.ReplaceOffer(offer['_self'], new_offer)\n",
    "else:\n",
    "    print(throughput, \"is not a valid throughput for Cosmos DB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create documents\n",
    "\n",
    "You can use the Python SDK to create new documents in our collection. For this we will use some sample documents, that are used as well in the [EDX course for Cosmos DB](https://courses.edx.org/courses/course-v1:Microsoft+DAT237x+2T2017/course/). In that course these documents are used to illustrate the .NET API, we will use them here for the Python SDK.\n",
    "\n",
    "The function insert_item supports a \"pretrigger\" argument, please ignore it for the time being (we will come back to it later in this tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need these throughout the notebook\n",
    "import os, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single add\n",
    "def insert_item(client, coll_link, item, pretrigger=None):\n",
    "    options={}\n",
    "    if pretrigger:\n",
    "        options['preTriggerInclude'] = pretrigger\n",
    "    client.CreateItem(coll_link, item, options)\n",
    "\n",
    "# Add all documents in a specific folder\n",
    "def insert_items_batch(client, coll_link, data_dir):\n",
    "    jsonpath = os.path.join(os.getcwd(), data_dir)\n",
    "    counter=0\n",
    "    for file in os.listdir(jsonpath):\n",
    "        if file[-5:] == \".json\":\n",
    "            #print(\"Found json file\", file)\n",
    "            f=open(os.path.join(jsonpath, file), 'r')\n",
    "            item_json = f.read()\n",
    "            item = json.loads(item_json)\n",
    "            insert_item(client, coll_link, item)\n",
    "            counter += 1\n",
    "        else:\n",
    "            print(\"Non-JSON file found:\", file)\n",
    "    print(counter, \"documents added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_items_batch(client, coll_link, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying documents\n",
    "\n",
    "Now that we have some data in the collection, we can start running some queries. Let us start with something simple. As you can see, the send_query function supports defining query options, we will see those in a minute. See the reference documentation for the [QueryItems](https://docs.microsoft.com/en-us/python/api/azure-cosmos/azure.cosmos.cosmos_client.cosmosclient?view=azure-python#queryitems-database-or-container-link--query--options-none--partition-key-none-) method for more information.\n",
    "\n",
    "In the example below, for output clarity the send_query function has an optional toggle that can be used to hide the actual results, and print only the number of matching documents, as well as the RU/s consumed by this particular query. Note how the consumed RU's are obtained by looking at a specific field of the client object, that contains the consumed RU's for the last operation.\n",
    "\n",
    "You can find more examples of queries for Azure Cosmos DB [here](https://docs.microsoft.com/azure/cosmos-db/how-to-sql-query)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function that we will use to send a query to a collection\n",
    "def send_query(client, coll_link, query, options=None, show_results=True):\n",
    "    docs = list(client.QueryItems(coll_link, query, options))\n",
    "    for doc in docs:\n",
    "        if show_results:\n",
    "            print(json.dumps(doc, indent=4, sort_keys=True))\n",
    "    print(len(docs), 'items found,', client.last_response_headers['x-ms-request-charge'], 'RU/s consumed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query with partition ID\n",
    "customer_id='09d2bb28e9c54bc581492d542789f2ad'\n",
    "source='other'\n",
    "query = 'SELECT * FROM customers WHERE customers.source=\\'{0}\\' AND customers.id=\\'{1}\\''.format(source, customer_id)\n",
    "send_query(client, coll_link, query, show_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you leave out the source in the query, as the example below, Cosmos DB is forced to look into every partition. Hence, if you do not specify in the options that this is to be a cross-partition query, you will get an error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query without partition ID\n",
    "customer_id='09d2bb28e9c54bc581492d542789f2ad'\n",
    "options = {} \n",
    "options['enableCrossPartitionQuery'] = True\n",
    "query = 'SELECT * FROM customers WHERE customers.id=\\'{0}\\''.format(customer_id)\n",
    "send_query(client, coll_link, query, options=options, show_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have seen in the code for send_query, you can send some options along with the query, that will modify the way in which the query is executed. For example, we can enable cross-partition queries (to be able to select all records) and set the maximum item count to 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple query with options\n",
    "query = 'SELECT * FROM customers'\n",
    "options = {} \n",
    "options['enableCrossPartitionQuery'] = True\n",
    "options['maxItemCount'] = 2\n",
    "send_query(client, coll_link, query, options, show_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex queries are supported using the SQL dialect of Cosmos DB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query showing projection and filtering\n",
    "query='''SELECT {\n",
    "     \"full-name\": customers.name,\n",
    "     \"contact-details\": {\n",
    "        \"phone\": customers.phone,\n",
    "        \"address\": customers.address\n",
    "    },\n",
    "     \"employment\": {\n",
    "        \"employer\": customers.company,\n",
    "        \"work-email\": customers.email\n",
    "     }\n",
    "} AS person\n",
    "FROM customers\n",
    "WHERE customers.source = \"retail-location\"'''\n",
    "options = {} \n",
    "options['enableCrossPartitionQuery'] = True\n",
    "send_query(client, coll_link, query, options, show_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triggers\n",
    "\n",
    "Triggers are activites that can be executed before (\"Pre\" triggers) or after (\"Post\" triggers) data being written or updated in Cosmos DB. Triggers are written in JavaScript, which makes working with JSON very easy. In this repository we have a trigger that adds a 'department' property to a document before adding it to the collection, in case that property did not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "trigger_filename = os.path.join(os.getcwd(), 'triggers', 'validateDepartmentExists.js')\n",
    "f=open(trigger_filename, 'r')\n",
    "trigger_code = f.read()\n",
    "print(trigger_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cosmos.documents as documents\n",
    "\n",
    "# Create new trigger from file\n",
    "def create_trigger(client, coll_link, filename):\n",
    "    with open(filename) as file:\n",
    "        file_contents = file.read()\n",
    "    trigger_name = os.path.splitext(os.path.basename(filename))[0]\n",
    "    trigger_definition = {\n",
    "        'id': trigger_name,\n",
    "        'serverScript': file_contents,\n",
    "        'triggerType': documents.TriggerType.Pre,\n",
    "        'triggerOperation': documents.TriggerOperation.All\n",
    "    }\n",
    "    trigger = client.CreateTrigger(coll_link, trigger_definition)\n",
    "\n",
    "# List existing defined triggers in the collection\n",
    "def query_triggers(client, coll_link):\n",
    "    trigger_query = 'select * from r'\n",
    "    triggers = list(client.QueryTriggers(coll_link, trigger_query))\n",
    "    for trigger in triggers:\n",
    "        print(json.dumps(trigger, indent=4, sort_keys=True))\n",
    "\n",
    "    \n",
    "trigger_filename = os.path.join(os.getcwd(), 'triggers', 'validateDepartmentExists.js')\n",
    "create_trigger(client, coll_link, trigger_filename)\n",
    "query_triggers(client, coll_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add a new document without the 'department' property, and verify that the property was added by the Trigger. For that we will use a helper function that generates a customer with a random ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, string\n",
    "\n",
    "def get_random_item():\n",
    "    random_id = ''.join(random.choices(string.ascii_lowercase + string.digits, k=16))\n",
    "    itemToCreate = {\n",
    "        'firstName': 'Sample',\n",
    "        'lastName': 'Person',\n",
    "        'id': random_id,\n",
    "        'source': 'random'\n",
    "    }\n",
    "    return itemToCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_item = get_random_item()\n",
    "print('We will send an item without the \\'department\\' property:')\n",
    "print(random_item)\n",
    "# Note that we do specify the ID of the Pre trigger to execute\n",
    "insert_item(client, coll_link, random_item, pretrigger='validateDepartmentExists')\n",
    "print(\"And now the item actually created should have the \\'department\\' property, added by the trigger:\")\n",
    "query = 'SELECT * FROM customers WHERE customers.id = \\'{0}\\''.format(random_item['id'])\n",
    "options = {} \n",
    "options['enableCrossPartitionQuery'] = True\n",
    "send_query(client, coll_link, query, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Defined Functions (UDF)\n",
    "\n",
    "You can define your own functions that can be used in queries. In this section we are going to create a user-defined function (UDF) that converts from US dollars to euros. The function is in the \"udf\" directory of this repository. First we will add the function to the collection: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UDF from a file with JS code\n",
    "def create_udf(client, coll_link, filename):\n",
    "    udf_name = os.path.splitext(os.path.basename(filename))[0]\n",
    "    if get_udf(client, coll_link, udf_name):\n",
    "        print(\"UDF\", udf_name, \"already exists, you might want to update it instead\")\n",
    "    else:\n",
    "        with open(filename) as file:\n",
    "            file_contents = file.read()\n",
    "        udf_definition = {\n",
    "            'id': udf_name,\n",
    "            'serverScript': file_contents,\n",
    "        }\n",
    "        return client.CreateUserDefinedFunction(coll_link, udf_definition)\n",
    "\n",
    "# Get UDF by name\n",
    "def get_udf(client, coll_link, udf_name):\n",
    "    udf_query = 'select * from r where r.id =\"' + udf_name + '\"'\n",
    "    udfs = list(client.QueryUserDefinedFunctions(coll_link, udf_query))\n",
    "    if len(udfs) > 0:\n",
    "        return udfs[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "create_udf(client, coll_link, os.path.join(os.getcwd(), 'udf', 'convertToEuro.js'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now verify that the UDF has been properly created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_udfs(client, coll_link):\n",
    "    udf_query = 'select * from r'\n",
    "    udfs = list(client.QueryUserDefinedFunctions(coll_link, udf_query))\n",
    "    for udf in udfs:\n",
    "        print(json.dumps(udf, indent=4, sort_keys=True))\n",
    "\n",
    "# Verify the function is created\n",
    "query_udfs(client, coll_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to modify the function (for example if you change the original file), you can use the ReplaceUserDefinedFunction method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update existing UDF with a file\n",
    "def update_udf(client, coll_link, udf_name, filename):\n",
    "    udf_query = 'SELECT * from r WHERE r.id = \"' + udf_name + '\"'\n",
    "    udfs = list(client.QueryUserDefinedFunctions(coll_link, udf_query))\n",
    "    if len(udfs) > 0:\n",
    "        udf_link = udfs[0]['_self']\n",
    "        with open(filename) as file:\n",
    "            file_contents = file.read()\n",
    "        udf_definition = {\n",
    "                    'id': udf_name,\n",
    "                    'body': file_contents,\n",
    "                }\n",
    "        client.ReplaceUserDefinedFunction(udf_link, udf_definition)\n",
    "    else:\n",
    "        print(\"UDF\", udf_name, \"not found!\")\n",
    "\n",
    "update_udf(client, coll_link, 'convertToEuro', os.path.join(os.getcwd(), 'udf', 'convertToEuro.js'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to use the function inside of a simple query. Note the higher RU consumption (you can try to execute the same query without the UDF to compare):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT TOP 1 c.name, c.balance, udf.convertToEuro(c.balance) AS balanceEUR FROM customers c WHERE c.source = \"word-of-mouth\"'\n",
    "options = {} \n",
    "options['enableCrossPartitionQuery'] = True\n",
    "send_query(client, coll_link, query, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stored procedures\n",
    "\n",
    "The SQL API of Cosmos DB supports stored procedures, that can be used for multiple objectives, such as for example to provide transaction semantics in Cosmos DB. You can find more information in the Cosmos DB documentation about [how to write stored procedures](https://docs.microsoft.com/en-us/azure/cosmos-db/how-to-write-stored-procedures-triggers-udfs#stored-procedures).\n",
    "\n",
    "In this notebook we will use a stored procedure to perform a transfer between the balance of two customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the stored procedure\n",
    "def create_sproc(client, s_coll, filename):\n",
    "    sproc_name = os.path.splitext(os.path.basename(filename))[0]\n",
    "    if get_sproc(client, coll_link, sproc_name):\n",
    "        print(\"Stored Procedure\", sproc_name, \"already exists, you might want to update it instead\")\n",
    "    else:\n",
    "        with open(filename) as file:\n",
    "            file_contents = file.read()\n",
    "        sproc_definition = {\n",
    "                    'id': sproc_name,\n",
    "                    'serverScript': file_contents,\n",
    "                }\n",
    "        sproc = client.CreateStoredProcedure(coll_link, sproc_definition)\n",
    "\n",
    "# Get stored procedure by name\n",
    "def get_sproc(client, coll_link, sproc_name):\n",
    "    sproc_query = 'select * from r where r.id =\"' + sproc_name + '\"'\n",
    "    sprocs = list(client.QueryStoredProcedures(coll_link, sproc_query))\n",
    "    if len(sprocs) > 0:\n",
    "        return sprocs[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "create_sproc(client, coll_link, os.path.join(os.getcwd(), 'storedproc', 'TransferBalance.js'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can verify that the stored procedure has been created correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the list of existing store procedures\n",
    "def query_sproc(client, coll_link):\n",
    "    sp_query = 'select * from r'\n",
    "    sprocs = list(client.QueryStoredProcedures(coll_link, sp_query))\n",
    "    for sproc in sprocs:\n",
    "        print(json.dumps(sproc, indent=4, sort_keys=True))\n",
    "\n",
    "query_sproc(client, coll_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to change the stored procedure, you can use this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To update an existing stored procedure\n",
    "def update_sproc(client, coll_link, sproc_name, filename):\n",
    "    sp_query = 'SELECT * from r WHERE r.id = \"' + sproc_name + '\"'\n",
    "    sprocs = list(client.QueryStoredProcedures(coll_link, sp_query))\n",
    "    if len(sprocs) > 0:\n",
    "        sproc_link = sprocs[0]['_self']\n",
    "        with open(filename) as file:\n",
    "            file_contents = file.read()\n",
    "        sproc_definition = {\n",
    "                    'id': sproc_name,\n",
    "                    'body': file_contents,\n",
    "                }\n",
    "        client.ReplaceStoredProcedure(sproc_link, sproc_definition)\n",
    "    else:\n",
    "        print(\"Stored procedure\", sproc_name, \"not found!\")\n",
    "\n",
    "update_sproc(client, coll_link, 'TransferBalance', os.path.join(os.getcwd(), 'storedproc', 'TransferBalance.js'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define a function to execute the stored procedure, and send some balance from one customer to another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute stored procedure\n",
    "def execute_sproc_transferBalance(partition_value, id_from, id_to, amount):\n",
    "    sp_name = 'TransferBalance'\n",
    "    sp_query = 'SELECT * from r WHERE r.id = \"' + sp_name + '\"'\n",
    "    sprocs = list(client.QueryStoredProcedures(coll_link, sp_query))\n",
    "    if len(sprocs) > 0:\n",
    "        sproc_link = sprocs[0]['_self']\n",
    "        options = {\n",
    "            'setScriptLoggingEnabled': True,\n",
    "            'partitionKey': partition_value\n",
    "        }\n",
    "        sproc_response = client.ExecuteStoredProcedure(sproc_link, params=[id_from, id_to, amount], options=options)\n",
    "        # The response is the ID of the created resource, not a dictionary as the doc seems to suggest\n",
    "        # https://docs.microsoft.com/en-us/python/api/azure-cosmos/azure.cosmos.cosmos_client.cosmosclient?view=azure-python#executestoredprocedure-sproc-link--params--options-none-\n",
    "        print(type(sproc_response), ':', sproc_response)\n",
    "    else:\n",
    "        print(\"Stored procedure\", sp_name, \"not found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally run our transaction using the stored procedure. The following code has two customer IDs in the same partition `word-of-mouth`. When you run the code as-is, you should see that $100 has been transfered from the customer1 (Benton Cooley) to the customer2 (Warren Holman).\n",
    "\n",
    "However, if you uncomment the third line (`id2=\"09d2bb28e9c54bc581492d542789f2ad\"`) you will find receive an error message: `Unable to find second customer`. This is because transactions in Azure Cosmos DB are limited to a single partition, and the ID in this third line corresponds to Giliam Greener, with source='other' and hence in a different subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1=\"1240d84bd5f44074b36bd1977bc9062c\"\n",
    "id2=\"5c89c87d34e64f37a3c8fae3fb86d8fc\"\n",
    "# id2=\"09d2bb28e9c54bc581492d542789f2ad\"\n",
    "amount_to_transfer = 100\n",
    "query = 'SELECT c.name, c.source, c.balance, c.id FROM customers c WHERE c.id IN (\"{0}\", \"{1}\")'.format(id1, id2)\n",
    "options = {} \n",
    "options['enableCrossPartitionQuery'] = True\n",
    "send_query(client, coll_link, query, options=options)\n",
    "execute_sproc_transferBalance('word-of-mouth', id1, id2, amount_to_transfer)\n",
    "send_query(client, coll_link, query, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change feed\n",
    "\n",
    "The change feed is an extremely interesting feature of Cosmos DB, since it enables many usage scenarios such as data replication, triggering serverless computing such as Azure Functions, or cost-effective data deletions, to name a few. You can find more information about Azure Cosmos DB change feed [here](https://docs.microsoft.com/azure/cosmos-db/change-feed).\n",
    "\n",
    "<img src=\"figures/changefeedoverview.png\" width=\"700\"/>\n",
    "\n",
    "The following code shows how to get the change feed from the creation of the database, and how to use the etag header to ask for changes occurred since the last query to the feed, which after creating one document, should be only one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_change_feed(client, coll_link, continuation=None, show_results=True):\n",
    "        options = {}\n",
    "        #options['partitionKeyRangeId'] = ''\n",
    "        if continuation:\n",
    "            options['continuation'] = continuation\n",
    "        else:\n",
    "            options[\"startFromBeginning\"] = True\n",
    "        response = client.QueryItemsChangeFeed(coll_link, options)\n",
    "        if show_results:\n",
    "            i=0\n",
    "            for doc in response:\n",
    "                print(doc)\n",
    "                i += 1\n",
    "            count = i\n",
    "        else:\n",
    "            count = len(tuple(response))\n",
    "        print(count, \"change feed items found, continuation\", client.last_response_headers['etag'])\n",
    "        \n",
    "get_change_feed(client, coll_link, show_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuation=client.last_response_headers['etag']\n",
    "insert_item(client, coll_link, get_random_item())\n",
    "get_change_feed(client, coll_link, continuation=continuation, show_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can have a look at [this sample code](https://github.com/Azure/azure-cosmos-python/blob/master/samples/ChangeFeedManagement/Program.py) for more on handling the Azure Cosmos DB Change feed with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "In order to save costs you can delete the resource group that was created at the beginning of this exercise via the Azure CLI (or any other method). Please be careful with this command, since it will delete the resource group as well as every resource inside, including the Cosmos DB account and all databases and collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az group delete -n $rg -y --no-wait"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
